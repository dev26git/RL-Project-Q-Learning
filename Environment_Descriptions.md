Environment Descriptions:

1. Env_1: Q-Learning
    - is_slippery = False
    - learning_rate_a = 0.9
    - discount_factor_g = 0.9
    - epsilon_decay_rate = 0.0001
    - Episodes = 15000
<br><br>
2. Env_2: Q-Learning
    - is_slippery = False
    - learning_rate_a = 0.9
    - discount_factor_g = 0.9
    - epsilon_decay_rate = 0.00001
    - Episodes = 150000
<br><br>
3. Env_3: Q-Learning
    - is_slippery = True
    - learning_rate_a = 0.9
    - discount_factor_g = 0.9
    - epsilon_decay_rate = 0.0001
    - Episodes = 15000
<br><br>
4. Env_4: Q-Learning
    - is_slippery = False
    - learning_rate_a = 0.9
    - discount_factor_g = 0.9
    - epsilon_decay_rate = 0.0001
    - Episodes = 15000
    - goal_reward = 15, hole_penalty = -2, step_penalty = -0.5
<br><br>
5. Env_5: Q-Learning<br>
    A)
    - is_slippery = False
    - learning_rate_a = 0.9
    - discount_factor_g = 0.9
    - epsilon_decay_rate = 0.0001
    - Episodes = 15000
    - goal_reward = 23, hole_penalty = -2, step_penalty = -1<br>
    
    B)
    - is_slippery = False
    - learning_rate_a = 0.9
    - discount_factor_g = 0.1
    - epsilon_decay_rate = 0.0001
    - Episodes = 15000
    - goal_reward = 23, hole_penalty = -2, step_penalty = -1
<br><br>
6. Env_6: Q-Learning
    - Enhanced Frozen Lake env
<br><br>
7. Env_7: Double Q-Learning<br>
    - is_slippery = False
    - learning_rate_a = 0.9
    - discount_factor_g = 0.1
    - epsilon_decay_rate = 0.0001
    - Episodes = 15000
    - goal_reward = 23, hole_penalty = -2, step_penalty = -1